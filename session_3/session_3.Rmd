
# **Class Notes**

[Lecture Notes](lecture_notes.Rmd)

> All of the scripts and batch files are hyperlinked within the text.

## **Sequence Data Quality Control & Adaptor Trimming**

1. Login to OSCER

`ssh [YOUR_ACCOUNT_ID]@schooner.oscer.ou.edu`

2. Activate environment

`mamba activate /home/mbtoomey/.conda/envs/BIOL7263_Genomics`

3. Create **[sbatch](scripts/trim_galore.sbatch)** and **[sh](scripts/trim_galore.sh)** files for SLRM submission.

4. Run trim_galore and look for 1) MiSeq 2) paired end or 3) Illumina 1.9+

`trim_galore --illumina --paired --phred33 /scratch/biol726310/BIOL7263_Genomics/sequencing_data/ecoli/read_1.fastq.gz/scratch/biol726310/BIOL7263_Genomics/sequencing_data/ecoli/read_2.fastq.gz `

`trim_galore --paired --fastqc --gzip --cores 4 --length 100 /scratch/biol726310/BIOL7263_Genomics/trim_galore read_1.fastq.gz /scratch/biol726310/BIOL7263_Genomics/sequencing_data/ecoli/read_2.fastq.gz --basename trimmed_reads -o /scratch/biol726310/BIOL7263_Genomics/trim_galore/`

5. Submit the job
`sbatch /home/biol726310/BIOL7263_Genomics/scripts/trim_galore/trim_galore.sbatch`

6. Check on job
`squeue -u biol726310`

7. We can count the lines after trimming

`zcat trimmed_reads_val_1.fq.gz | wc -l`

`zcat trimmed_reads_val_2.fq.gz | wc -l`

## **Random Subsampling and Digital Normalisation**

- Oftentimes, the data obtained from analyses may be overwhelming for your local computer. This can be circumvented by creating random subsamples of the trimmed data. We can then perform assembly with this subsampled data.

1. Login to OSCER

`ssh [YOUR_ACCOUNT_ID]@schooner.oscer.ou.edu`

2. Activate environment

`mamba activate /home/mbtoomey/.conda/envs/BIOL7263_Genomics`

3. We will use the program seqtk which is a toolkit for FASTA/Q processing

`seqtk`
`seqtk sample`

4. Randomly sampling 10% of the dataset. 10% is expressed as a decimal. This will create two different random samples. 

`seqtk sample trimmed_reads_val_1.fq.gz 0.1 > trimmed_reads_val_1_subsample_one.fq`

`seqtk sample trimmed_reads_val_1.fq.gz 0.1 > trimmed_reads_val_1_subsample_two.fq`

`head trimmed_reads_val_1_subsample*`

5. As you will notice, the sub samples are the same. This is because the same seed is used and is assigned as the standard method. We have to change the seed option to get genuinely random samples with different seeds. We can use the `-s ___` to set the seed of our random samples.

`seqtk sample -s 1234 trimmed_reads_val_1.fq.gz 0.1 > trimmed_reads_val_1_subsample_three.fq`

`seqtk sample -s 5678 trimmed_reads_val_1.fq.gz 0.1 > trimmed_reads_val_1_subsample_four.fq`

`head trimmed_reads_val_1_subsample_three.fq`

`head trimmed_reads_val_1_subsample_four.fq`

6. We are going to clean up the files and add the same seed so that the analyses are the same going forward.

`rm *.fq`

`seqtk sample -s 628 trimmed_reads_val_1.fq.gz 0.5 > trimmed_reads_val_1_subsampled.fq`

`seqtk sample -s 628 trimmed_reads_val_2.fq.gz 0.5 > trimmed_reads_val_2_subsampled.fq`

7. We need to zip the the files but seqtk cannot produce them. For this, we will use `gzip` or `pigz`.

`pigz *.fq`


## Digital Normalisation

- Digital normalization is a computational technique used to reduce redundancy and improve the efficiency of downstream analysis for high-throughput sequencing data, particularly FASTQ files generated by Illumina sequencers. BBNorm from the BBtools package is a great technique for this.


## Contaminant checking

- A number of tools are available which also enable to you to quickly search through your reads and assign them to particular taxa or taxonomic groups. These can serve as a quick check to make sure your samples or libraries are not contaminated with DNA from other sources. If you are performing a de-novo assembly, for example, and have DNA sequences present from multiple organisms, you will risk poor results and chimeric contigs.

## **Aligning Illumina Data to a Reference Sequence**

- Now that we have checked the quality of our raw data, we can begin the process of aligning the trimmed reads against a reference sequence. In this way we can compare how the reference sequence, and the strain we are interested in compare. We will be using **BWA (Burrows-Wheeler aligner)**.

- By mapping reads against a reference, what we mean is that we want to go from a FASTQ file of lots of reads and a FASTA file with a set of contiguous sequences, to another type of file (described later) that lists the reads AND where/if those reads map (align) against the reference.

## Sequencing Error

- As an example, a region highlighted in green (other colors) on may show that most reads agree with the reference sequence (i.e. the C-base). However, two reads near the bottom show an A-base. In this situation we can safely assume that the A-bases are due to a sequencing error rather than a genuine variant since the ‚Äòvariant‚Äô has only one read supporting it. If this occurred at a higher frequency however, we would struggle to determine whether it was a genuine variant or an error.

## PCR Duplication

- As another example, a highlighted region in red shows what appears to be a variant. A C-base is present in the reference and half the reads, whilst an A-base is present in a set of reads which all start at the same position.

- So we must ask, is this a genuine difference or a sequencing or sample preparation error? What do you think? If this was a real sample, would you expect all the reads containing an A-base to start at the same location?

- The answer is probably not. This 'SNP' is in fact probably an artifact of PCR duplication - i.e. the same fragment of DNA has been replicated many times more than the average and happens to contain an error at the first position. We can filter out such reads after mapping to the reference (we will do this shortly).

- It's always important to think critically about any findings - don't assume that whatever bioinformatic tools you are using are perfect. Or that you have used them perfectly.

## **Generating an Index**

- Before we can start aligning reads to a reference genome, the genome sequence needs to be 'indexed', this means sorting the genome into easily searched chunks (similar to a book's index).

- Today we are using "BWA", but you may have read that is it deprecated/superceded by "minimap2" and there is a nice [blog](https://lh3.github.io/2018/04/02/minimap2-and-the-future-of-bwa)üîç about it here.

1. Login to OSCER

`ssh [YOUR_ACCOUNT_ID]@schooner.oscer.ou.edu`

2. Activate environment

`mamba activate /home/mbtoomey/.conda/envs/BIOL7263_Genomics`

3. Looking at the BWA program.

`BWA`

4. Making a directory for our script that we will submit to OSCER.

`mkdir /home/biol726310/BIOL7263_Genomics/scripts/BWA/`


5. We will add the following line of code to our script called **[ecoli_index.sh](scripts/ecoli_index.sh)**. We will also need to make our sbatch file called **[ecoli_index.sbatch](scripts/ecoli_index.sbatch)**. Here the -p option sets the output folder, so our index will be written to the same location as our refrence sequence

`bwa index /scratch/biol726310/BIOL7263_Genomics/reference_sequences/ecoli/GCF_000005845.2_ASM584v2_genomic.fna -p /scratch/biol726310/BIOL7263_Genomics/reference_sequences/ecoli/GCF_000005845.2_ASM584v2_genomic`

6. Submit the job

`sbatch /home/biol726310/BIOL7263_Genomics/scripts/BWA/ecoli_index.sbatch`

6. Check on job

`squeue -u biol726310`

## **Mapping Reads to the Indexed Reference Sequence**
- Now we can begin to align 'read_1' and 'read_2' to the reference genome. First of all change back into raw reads directory where we made the trimmed and QC reads, and then create a subdirectory to contain our mapping results.

1. Login to OSCER

`ssh [YOUR_ACCOUNT_ID]@schooner.oscer.ou.edu`

2. Activate environment

`mamba activate /home/mbtoomey/.conda/envs/BIOL7263_Genomics`

3. Now we can 

`cd /scratch/mbtoomey/BIOL7263_Genomics/sequencing_data/ecoli/`

`mkdir mapping_to_reference`

`cd mapping_to_reference`

4. Looking at `bwa mem`

- From this we can see that we need to provide BWA with a set of FASTQ files containing the raw reads (denoted by '<in.fq>' meaning required and '[in2.fq]' as optional) and a reference file (unhelpfully this is listed as '<idxbase>') and any other options we wish to change.

5. Beginning the alignment process

- Our reference sequences are in the file:
`/scratch/biol726310/BIOL7263_Genomics/reference_sequences/ecoli/GCF_000005845.2_ASM584v2_genomic.fna`

- Our filtered reads are in the files:
`/scratch/biol726310/BIOL7263_Genomics/sequencing_data/ecoli/trimmed_reads_val_1.fq.gz`

`/scratch/biol726310/BIOL7263_Genomics/sequencing_data/ecoli/trimmed_reads_val_2.fq.gz`


In order to align our paired reads using multi-threading, and output to a file called ecoli_mapped.sam. We will set the output '-o' to ecoli_mapped.sam and the number of threads/processes the program should use ('-t').


We will create the .sh file called **[ecoli_bwa_mem.sh](scripts/ecoli_bwa_mem.sh)** with the above commands updated for your file system and a .sbatch file called **[ecoli_bwa_mem.sbatch](scripts/ecoli_bwa_mem.sbatch)** with the 'n-task = 4' option, upload to the scripts/BWA folder and submit the job.

It seems that we may need to have the trimmed reads in a similar folder (upstream folder), otherwise, we cannot access the data.


6. Submit the job

`sbatch /home/biol726310/BIOL7263_Genomics/scripts/BWA/ecoli_bwa_mem.sbatch`

7. Check on job

`squeue -u biol726310`

Stopped right before task 7.

## **SAM File Manipulation**
- Before we can visualize the alignment in a more meaningful way, it is beneficial to convert the SAM file into a BAM file (Binary AlignMent format) for several reasons. SAM files are great for human readability, but they are not so good for fast computational access. The binary format will allow speedy access to the information stored within it, and it also reduces the file size on the disk.

- To convert the SAM file to a BAM file we will use another program called **samtools**.

1. Login to OSCER

`ssh [YOUR_ACCOUNT_ID]@schooner.oscer.ou.edu`

2. Activate environment

`mamba activate /home/mbtoomey/.conda/envs/BIOL7263_Genomics`

3. View samtools

`samtools view`

- We can see that we need to provide 'samtools view' with a reference genome as a FASTA formatted file '-T', the '-b' and '-S' options to indicate that the output should be in BAM format, and that the input is in SAM format, all along with the alignment input file itself - e.g.

We will upload the following **[sbatch](scripts/ecoli_samtools_view.sbatch)** and **[sh/script](scripts/ecoli_samtools_view.sh)** files to convert the SAM into a BAM file.


Now that we have the BAM file, we are able to sort the BAM file as desired. We uploaded the following **[sbatch](scripts/samtools_sort.sbatch)** and **[sh/script](scripts/samtools_sort.sh)** files to sort the BAM file.


## **Efficiency for the previous steps**

- We have aligned trimmed reads to a reference genome, converted SAM to BAM and sorted the BAM file. It is much faster to create one pipeline with all the steps involved. 

The following files were submitted to OSCER 1) **[sbatch](scripts/ecoli_map_sort.sbatch)** and **[sh/script](scripts/ecoli_map_sort.sh)**.



## Removing suspected PCR duplicates

- The program 'samtools' can do a reasonably good job of removing potential PCR duplicates, especially when using paired-end read data 

First we need to sort the BAM by 'read name'. The  command after this requires that the BAM is sorted in this way.

Next we will instruct 'samtools' to add special 'ms' and 'MC' tags for the 'samtools markdup' program to use later on. This is because 'BWA' can sometimes leave unusual FLAG information in the 'SAM' file records.

We then re-sort our BAM file by chromosomal/position coordinates. We have to be careful with the position of the output file.

We can now mark the duplicates and remove them with the '-r' option.

The following is applied to the

**[script](scripts/ecoli_markdup.sh)** and **[sbatch](scripts/ecoli_markdup.sbatch)** files.

Most programs used to view the BAM formatted data require an index file to locate the reads mapping to a particular location quickly. We did this for our reference genome file. The **[script](scripts/bam_index.sh)** and **[sbatch](scripts/bam_index.sbatch)** files are included here.

## **Mapping Statistics**

- Now we can begin to generate some summary statistics. We can run the following line of code on the login node (if so,we have to alter the path based on our location). 

```bach
samtools flagstat ecoli_mapped_namesort_fixmate_sort_markdup.bam > mappingstats.txt
```
If we were to incorporate this into a script, we would want to include the entire path.

```bach
samtools flagstat /scratch/biol726310/BIOL7263_Genomics/sequencing_data/ecoli/mapping_to_reference/ecoli_mapped_namesort_fixmate_sort_markdup.bam > /scratch/biol726310/BIOL7263_Genomics/sequencing_data/ecoli/mapping_to_reference/mappingstats.txt
```

## Cleaning up

- It is generally good practice to keep your intermediary files whilst you are continuing your analysis, but in this case we really don't need some of the extra files we have created during this process. Indeed, we are only really interested in the final file 'ecoli_mapped_namesort_fixmate_sort_markdup.bam'.

Two approaches:

```bach
rm ecoli_mapped.bam
rm ecoli_mapped.sam
rm ecoli_mapped_namesort.bam
rm ecoli_mapped_namesort_fixmate.bam
rm ecoli_mapped_namesort_fixmate_sort.bam
rm ecoli_mapped_sorted.bam
```
This approach is more advisable as the data is fairly large but would require making a script and submitting an sbatch file.

```bach
rm /scratch/biol726310/BIOL7263_Genomics/sequencing_data/ecoli/mapping_to_reference/ecoli_mapped.bam
rm /scratch/biol726310/BIOL7263_Genomics/sequencing_data/ecoli/mapping_to_reference/ecoli_mapped.sam
rm /scratch/biol726310/BIOL7263_Genomics/sequencing_data/ecoli/mapping_to_reference/ecoli_mapped_namesort.bam
rm /scratch/biol726310/BIOL7263_Genomics/sequencing_data/ecoli/mapping_to_reference/ecoli_mapped_namesort_fixmate.bam
rm /scratch/biol726310/BIOL7263_Genomics/sequencing_data/ecoli/mapping_to_reference/ecoli_mapped_namesort_fixmate_sort.bam
rm /scratch/biol726310/BIOL7263_Genomics/sequencing_data/ecoli/mapping_to_reference/ecoli_mapped_sorted.bam
```

## **QualiMap**

- Summarises the mapped alignments in much more detail than the mapping stats file we produced previously. It‚Äôs a technical tool which allows you to assess the sequencing for any problems and biases in the sequencing and the alignment rather than a tool to deduce biological features.

1. Login to OSCER

`ssh [YOUR_ACCOUNT_ID]@schooner.oscer.ou.edu`

2. Activate environment

`mamba activate /home/mbtoomey/.conda/envs/BIOL7263_Genomics`

3. View QualiMap

`qualimap bamqc`

To generate a 'QualiMap bamqc' report we can run the code in our **[script](scripts/qualmap.sh)** and submit the job to OSCER as a **[sbatch](scripts/qualmap.sbatch)** file.

4. Submit the job

`sbatch /home/biol726310/BIOL7263_Genomics/scripts/BWA/qualmap.sbatch`

5. Check on job

`squeue -u biol726310`

This will create a subfolder called 'bamqc' and a graphical report file **[qualimapReport.html](qualimapReport.html)**. There are a number of measures that this program will do. We will look at a few of them. We can also look at the **[genome_results.txt](genome_results.txt)** to view other statistics. There is also I folder that contains all of the images for the analysis.

## Coverage across the reference

- This displays the number of reads that cover each section of the genome. The red line shows a rolling average (about 175x). 

## Insert size histogram

- This displays the size of the DNA fragments. It shows how the DNA was selected before sequencing. 

## **IGV**

- Download **[IGV](https://igv.org/doc/desktop/#DownloadPage/)**


1. Load the genome reference and our alignments locally. 

**a) import the reference sequence**
- click on 'Genomes -> Load Genome from File...'
- select genome and click "Open"
- File type: `GCF_000005845.2_ASM584v2_genomic.fna (.fna file)`

**b) Import E. coli reference annotation**
- Load the annotation (.gff) by 'File -> Load from File...'.


**c) Load BAM alignment**
- Note that IGV requires the .bai index file to also be in the same directory (we generated that earlier with samtools index).
- Select 'File...' and 'Load From File...'. Select the BAM file and open.
- Note that you can load more BAM files if you wish to compare different samples, sequencing technologies or the results of different mapping programs.


## **SNPs and Indels**

### Manually Identify a Region Without any Reads Mapping
- This can be quite difficult to find even with a very small genome. Zoom out as far as you can, but where you are still able to see the read mappings.

- To be able to see this coverage information across the entire genome, regardless of how far you are zoomed out, you‚Äôll need to create a 'TDF file' which contains coverage information across windows of 'X' number of bases on the genome.

## **Manually Identify a Region Containing Repetitive Sequences**

- we could also try using the QualiMap reports from before to give you an idea where to look.

- Manual curation of SNPs and INDELs is a difficult and laborious task. 

- Only changes from the reference sequence are displayed in IGV
- Genuine SNPs/Indels should be present on both read 1 and read 2
- Genuine SNPs/Indels should be present on both strands
- Genuine SNPs/Indels should be supported by a good (i.e. 20-30x) depth of coverage
- Very important mutations (i.e. ones relied upon in a paper) should be confirmed via PCR/Sanger sequencing.

## **Automated Analyses**
- Viewing alignments is useful when convincing yourself, and your peers, that a particular mutation is real rather than an artefact, and for getting a feel for short read sequencing datasets. However, if we want to quickly and easily find variants we need to be able to generate lists of variants, and in which gene they occur (if any) and what effect that they might have. We also need to know which (if any) genes are missing (i.e. have zero coverage).

- To 'call' (predict) variants we can use a number of packages (e.g. VarScan, GATK, Picard Tools). However here, we will show you how to use the 'bcftools' package. First we need to generate a 'pileup' file which contains only the locations with the variants.

1. Login to OSCER

`ssh [YOUR_ACCOUNT_ID]@schooner.oscer.ou.edu`

2. Activate environment

`mamba activate /home/mbtoomey/.conda/envs/BIOL7263_Genomics`

3. View bfctools

`pfctools mpileup`


4. We will need to construct our **[script](scripts/ecoli_vcf.sh)** and **[sbatch](scripts/ecoli_vcf.sbatch)** files and submit a job to OSCER.


4. Submit the job

`sbatch /home/biol726310/BIOL7263_Genomics/scripts/variant_calling/ecoli_vcf.sbatch`

5. Check on job

`squeue -u biol726310`

Note that we are asking 'bcftools mpileup' to generate an uncompressed VCF output with the '-O v' option. The '-P Illumina' tells 'bcftools' that it is dealing with Illumina data, so that it can apply to the correct model to help account for mis-calls and/or indels.

This output by itself is not super useful on its own, as it contains information on each position in the genome. So let‚Äôs use 'bcftools' again to 'call' what it thinks are the variant sites. 

Here we have asked 'bcftools' to 'call' variants assuming a ploidy of 1, and to output only the variant sites in the 'VCF' format. We generated the **[script](scripts/ecoli_call.sh)** and **[sbatch](scripts/ecoli_call.sbatch)**.

```bach
grep -v -c  "^#" /scratch/biol726310/BIOL7263_Genomics/sequencing_data/ecoli/mapping_to_reference/var.called.vcf
```

Now we can filter this further, and with a tool made specifically to work with VCF files, in order to ensure we only retain regions where we have >90% allele frequency - we can do this with a tool called 'vcftools'. We will submit our **[script](scripts/ecoli_filt.sh)** and **[sbatch](scripts/ecoli_filt.sbatch)** files to OSCER for processing.

```bach
vcftools --minDP 10 --min-alleles 2 --max-alleles 2
--non-ref-af 0.9 --vcf /scratch/biol726310/BIOL7263_Genomics/sequencing_data/ecoli/mapping_to_reference/var.called.vcf --recode --recode-INFO-all --out /scratch/biol726310/BIOL7263_Genomics/sequencing_data/ecoli/mapping_to_reference/var.called.filt
```

You are safe to ignore any warnings that you see. This command creates a file called 'var.called.filt.recode.vcf'. Once complete, you can try viewing the file using the 'more' command (or your favourite text editor).

The lines starting with 'DP' and 'INDEL' contain various details concerning the variants. For haploid organisms, most of these details are not necessary. This forms our definitive list of variants for this sample.

We can now upload the CVF into our IGV program.

## **Locating Genes that are Missing Compared to the Reference**

- We can use a command from the BEDTools package to identify annotated genes which are not covered by reads across their full length.

We can upload our **[script](scripts/ecoli_cover.sh)** and **[sbatch](scripts/ecoli_cover.sbatch)** files to to find the genes that were not covered.

Take a look and you will see that the output contains one row per annotated gene, whereby the 13th (and final) column contains the proportion of the gene that is covered by reads from our sequencing. 1.00 means the gene is 100% covered and 0.00 means there is no coverage.

```bach
sort -t $'\t' -g -k 13 /scratch/biol726310/BIOL7263_Genomics/sequencing_data/ecoli/mapping_to_reference/gene_coverage.txt | less -S
```

It may be easier to view the data ommiting the annotation column, thus:


```bach
sort -t $'\t' -g -k 13 /scratch/biol726310/BIOL7263_Genomics/sequencing_data/ecoli/mapping_to_reference/gene_coverage.txt | cut -f1-8,10-13 | less -S

```






